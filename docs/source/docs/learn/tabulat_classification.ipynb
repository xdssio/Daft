{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's solve te titanic as if it was a real-world problem\n",
    "\n",
    "> we want to make it diverse enough such we can enusre we won't get stack the moment we'll use daft on real-world data \n",
    "\n",
    "### Pipeline steps\n",
    "* Cleaned cabin values that have illegal values are unnecessary, but it is crucial to take cleaning data into account, as it significantly affects the pipeline.\n",
    "* Calculating family_size = parch + sibsp + 1 (self)\n",
    "*  Get the Initials from the name, and map them to either \"Mr\", \"Miss\", \"Mrs\" and \"Other\".\n",
    "* Calculate the mean age for each Initial and use it to fill missing values for age.\n",
    "* Create age_group for each male/female and under/over the age of 15.\n",
    "* Bin family_size to the [0, 1, 2, 5, 7, 100,1000] bins.\n",
    "* Encode embarked, sex, family_bin, age_group with a label/one-hot encoder.\n",
    "* Use LightGBM for modelling.\n",
    "* Add the survived/died probability in a consumable way.\n",
    "\n",
    "### Context for applying prediction:\n",
    "* [MLFlow](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#pyfunc-create-custom)\n",
    "* [Ray-serve](https://docs.ray.io/en/latest/serve/getting_started.html)\n",
    "* [Cog](https://github.com/replicate/cog)\n",
    "* [FastAPI](http://fastapi.tiangolo.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:04:32.640495Z",
     "start_time": "2023-01-23T13:04:32.580618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home_dest</th>\n",
       "      <th>family_size</th>\n",
       "      <th>initial</th>\n",
       "      <th>age_group</th>\n",
       "      <th>family_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>adult female</td>\n",
       "      <td>(0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>adult male</td>\n",
       "      <td>(0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                           name     sex   age  sibsp  \\\n",
       "0       1         0  Allen, Miss. Elisabeth Walton  female  29.0      0   \n",
       "5       1         0            Anderson, Mr. Harry    male  48.0      0   \n",
       "\n",
       "   parch ticket      fare cabin embarked boat  body     home_dest  \\\n",
       "0      0  24160  211.3375    B5        S    2   NaN  St Louis, MO   \n",
       "5      0  19952   26.5500   E12        S    3   NaN  New York, NY   \n",
       "\n",
       "   family_size initial     age_group family_bin  \n",
       "0            1    Miss  adult female     (0, 1]  \n",
       "5            1      Mr    adult male     (0, 1]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('~/development/datasets/titanic.csv')\n",
    "target = 'survived'\n",
    "numeric_features = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
    "string_features = ['embarked', 'sex', 'family_bin', 'age_group']\n",
    "features = numeric_features\n",
    "df = df[df['cabin'].str.contains(' ') != True]\n",
    "df['family_size'] = df['parch'] + df['sibsp'] + 1\n",
    "df['initial'] = df['name'].str.extract(r'([A-Za-z]+)\\.')\n",
    "initials_map = {k: v for k, v in (zip(['Miss', 'Mr', 'Mrs', 'Mlle', 'Mme', 'Ms', 'Dr',\n",
    "                                       'Major', 'Lady', 'Countess',\n",
    "                                       'Jonkheer', 'Col', 'Rev',\n",
    "                                       'Capt', 'Sir', 'Don'],\n",
    "                                      ['Miss', 'Mr', 'Mrs', 'Miss', 'Miss', 'Miss',\n",
    "                                       'Mr', 'Mr', 'Mrs', 'Mrs',\n",
    "                                       'Other', 'Other', 'Other',\n",
    "                                       'Mr', 'Mr', 'Mr']))}\n",
    "df['initial'] = df['initial'].map(initials_map)\n",
    "\n",
    "train, test = train_test_split(df)\n",
    "means = train.groupby(['initial'])['age'].mean().to_dict()  # this should be with train\n",
    "\n",
    "for initial, value in means.items():\n",
    "    df['age'] = np.where((df['age'].isnull()) & (df['initial'].str.match(initial)), value, df['age'])\n",
    "\n",
    "df['age_group'] = None\n",
    "df.loc[((df['sex'] == 'male') & (df['age'] <= 15)), 'age_group'] = 'boy'\n",
    "df.loc[((df['sex'] == 'female') & (df['age'] <= 15)), 'age_group'] = 'girl'\n",
    "df.loc[((df['sex'] == 'male') & (df['age'] > 15)), 'age_group'] = 'adult male'\n",
    "df.loc[((df['sex'] == 'female') & (df['age'] > 15)), 'age_group'] = 'adult female'\n",
    "df['family_bin'] = pd.cut(df['family_size'], [0, 1, 2, 5, 7, 100, 1000])\n",
    "df['family_bin'] = df['family_bin'].astype(str)\n",
    "\n",
    "train = df.loc[train.index].dropna(subset=string_features)\n",
    "test = df.loc[test.index].dropna(subset=string_features)\n",
    "\n",
    "encoders = {column: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan,\n",
    "                                   ).fit(train[column].values.reshape(-1, 1)) for column in string_features}\n",
    "\n",
    "for column, encoder in encoders.items():\n",
    "    string_column = f\"le_{column}\"\n",
    "    train[string_column] = encoder.transform(train[column].values.reshape(-1, 1)).reshape(-1)\n",
    "    test[string_column] = encoder.transform(test[column].values.reshape(-1, 1)).reshape(-1)\n",
    "    features.append(string_column)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-23T13:45:34.591648Z",
     "start_time": "2023-01-23T13:45:33.215230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8296529968454258\n"
     ]
    }
   ],
   "source": [
    "# modelling\n",
    "model = LGBMClassifier()\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(test[target], model.predict(test[features]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daft approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class (pytorch lightning style)\n",
    "Seems like the first approach to try in terms of daft design.    \n",
    "First you clean, explore and write the functions during exploration and modelling. \n",
    "Secondly, you make a *Model* class to deploy including the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "\n",
    "    classifier: LightGBMClassifier(params)\n",
    "            \n",
    "    \n",
    "    def clean_cabin(self):\n",
    "        ...\n",
    "    \n",
    "    def calculate_family_size(self):\n",
    "        ...\n",
    "    \n",
    "    @polars_udf(return_type=str) \n",
    "    def clean_initlas(self):        \n",
    "        ...\n",
    "    \n",
    "    def _pre_predict(self, data):\n",
    "        \"\"\"feature engineering before predictions\"\"\"\n",
    "        ...\n",
    "    \n",
    "    @polars_udf(return_type=int)\n",
    "    def predict(self, data):        \n",
    "        return self.classifier.predict(self._pre_predict(data))\n",
    "            \n",
    "    \n",
    "    def fit(self, df):        \n",
    "        ...\n",
    "        self.classifier = self.classifier.fit(self._pre_fit(df))\n",
    "        \n",
    "    def transform(self):\n",
    "        ...\n",
    "        \n",
    "    def predict(self, df):\n",
    "        ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A static approach\n",
    "Simpler, and closer to POC, but less deploymnet friendly, as we need to save artifacts and code and manage both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft import polars_udf\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "@polars_udf(return_type=float)\n",
    "class LightGBM:\n",
    "\n",
    "    def __init__(self, classifier=None):        \n",
    "        self.classifier = classifier or _load_classifier()\n",
    "        \n",
    "    def _load_classifier():\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, a_data: pl.Series, b_data: pl.Series):\n",
    "        return np.matmul(self.model, np.array([a_data.to_numpy(), b_data.to_numpy()]))\n",
    "    \n",
    "\n",
    "@polars_udf(return_type=datetime.date)\n",
    "def clean_cabin(data):\n",
    "    ...\n",
    "    \n",
    "@polars_udf(return_type=datetime.date)\n",
    "def calculate_family_size(data):\n",
    "    ...\n",
    "\n",
    "train, test = df.ml.random_split() # or something similar\n",
    "\n",
    "def fit(df) # where does this code lives?\n",
    "\n",
    "    df = df.with_column(...) # clean\n",
    "    df = df.with_column(...) # calcualte size\n",
    "    model.fit(df)\n",
    "    return model\n",
    "\n",
    "model = fit(train) # artifact\n",
    "\n",
    "def predict(test, model): # where is this code managed?\n",
    "    \n",
    "    df = df.with_column(...) # calcualte size and other feature-engineering without removing droppong rows \n",
    "    return model.predict(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A state approach\n",
    "I consider it as a balanced approach. It relies on lazy evaluation on new data which daft don't have yet.   \n",
    "[PR Reference](https://github.com/Eventual-Inc/Daft/pull/496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft import polars_udf\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "@polars_udf(return_type=float)\n",
    "class LightGBM:\n",
    "\n",
    "    def __init__(self, classifier=None):\n",
    "        # Initialize and cache an \"expensive\" model between invocations of the UDF\n",
    "        self.classifier = classifier or _load_classifier()\n",
    "        \n",
    "    def _load_classifier():\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, a_data: pl.Series, b_data: pl.Series):\n",
    "        return np.matmul(self.model, np.array([a_data.to_numpy(), b_data.to_numpy()]))\n",
    "    \n",
    "\n",
    "@polars_udf(return_type=datetime.date)\n",
    "def clean_cabin(data):\n",
    "    ...\n",
    "    \n",
    "@polars_udf(return_type=datetime.date)\n",
    "def calculate_family_size(data):\n",
    "    ...\n",
    "\n",
    "train, test = df.ml.random_split() # or something similar\n",
    "\n",
    "train = train.with_column(...) # clean\n",
    "train = train.with_column(...) # calcualte size\n",
    "... # feature engineering\n",
    "train = train.with_column('prediction', LightGBM(df[features]))\n",
    "\n",
    "state = State.from_dataframe(train)\n",
    "\n",
    "state.inference(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn approach\n",
    "* Not sure exactly how to apply this - but this is the most standard solution today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleaner(df: daft.DataFrame): \n",
    "    \n",
    "    def fit():\n",
    "        ...\n",
    "        \n",
    "    def transform():\n",
    "        ...\n",
    "\n",
    "class FamilySize():\n",
    "    \n",
    "    def fit():\n",
    "        ...\n",
    "        \n",
    "    def transform():\n",
    "        ...\n",
    "        \n",
    "pipeline = sklearn.pipeline.Pipline([Cleaner, FamilySize,...,LightGBMClassifier])\n",
    "pipeline.fit(train)\n",
    "pipeline.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Unpublished notebook article](https://github.com/xdssio/goldilox/blob/master/notebooks/sklearn_vs_vaex_vs_pyspark.ipynb) \n",
    "\n",
    "Here you find a reference how it would look like in sklearn, pandas, Vaex(which is similar to the PR and state idea) and spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
